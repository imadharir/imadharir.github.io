<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Data Build Tool (Dbt) on Imad Harir</title>
        <link>https://imadharir.github.io/tags/data-build-tool-dbt/</link>
        <description>Recent content in Data Build Tool (Dbt) on Imad Harir</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <lastBuildDate>Mon, 30 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://imadharir.github.io/tags/data-build-tool-dbt/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Stock Market Real Time Data Analysis</title>
        <link>https://imadharir.github.io/p/stock-market-real-time-data-analysis/</link>
        <pubDate>Mon, 30 Sep 2024 00:00:00 +0000</pubDate>
        
        <guid>https://imadharir.github.io/p/stock-market-real-time-data-analysis/</guid>
        <description>&lt;img src="https://imadharir.github.io/p/stock-market-real-time-data-analysis/stockMarketDiagram.jpg" alt="Featured image of post Stock Market Real Time Data Analysis" /&gt;&lt;h1 id=&#34;google-cloud-pubsub-infrastructure-with-terraform&#34;&gt;Google Cloud Pub/Sub Infrastructure with Terraform
&lt;/h1&gt;&lt;p&gt;Â Â This project is focused on building a data pipeline for real-time stock market data analysis using Google Cloud Platform (GCP) and other open-source technologies. The pipeline ingests, processes, and analyzes stock market data to provide valuable insights.
Â Â This project automates the deployment of Google Cloud Pub/Sub resources using Terraform. The infrastructure includes a Pub/Sub topic and subscription, allowing for messaging between different components of the system.&lt;/p&gt;
&lt;h2 id=&#34;project-architecture&#34;&gt;Project Architecture
&lt;/h2&gt;&lt;p&gt;Below is the architecture of the project:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://imadharir.github.io/p/stock-market-real-time-data-analysis/stockMarketDiagram.jpg&#34;
	width=&#34;815&#34;
	height=&#34;586&#34;
	srcset=&#34;https://imadharir.github.io/p/stock-market-real-time-data-analysis/stockMarketDiagram_hu4688469147005051992.jpg 480w, https://imadharir.github.io/p/stock-market-real-time-data-analysis/stockMarketDiagram_hu7197408719458081956.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Architecture&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;139&#34;
		data-flex-basis=&#34;333px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;resources-deployed&#34;&gt;Resources Deployed
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Pub/Sub Topic&lt;/strong&gt;: A topic for sending messages.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pub/Sub Subscription&lt;/strong&gt;: A subscription to recpip install dotenveive messages from the topic.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cloud Storage Bucket&lt;/strong&gt;: A general-purpose bucket for data storage and ingestion.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cloud Function Storage Bucket&lt;/strong&gt;: A bucket to store the zip file containing the Cloud Function code.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cloud Function&lt;/strong&gt;: A serverless function triggered by Cloud Storage events to process data and load it into BigQuery.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;BigQuery Dataset&lt;/strong&gt;: A dataset for organizing tables in BigQuery.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;BigQuery Table&lt;/strong&gt;: A table for storing stock market data, with schema auto-detected.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;key-components&#34;&gt;Key Components
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;main.tf&lt;/code&gt;&lt;/strong&gt;: The entry point for the Terraform configuration, defining the provider (Google Cloud) and project-level settings.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;pubsub.tf&lt;/code&gt;&lt;/strong&gt;: Contains the configuration for creating the Pub/Sub topic and subscription.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;function.tf&lt;/code&gt;&lt;/strong&gt;: Defines the setup for the Google Cloud Function that processes data from Cloud Storage.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;functionBucket.tf&lt;/code&gt;&lt;/strong&gt;: Manages the Cloud Storage bucket specifically for storing Cloud Function code.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;dataset.tf&lt;/code&gt;&lt;/strong&gt;: Creates the BigQuery dataset that holds the table for stock market data.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;bq_table&lt;/code&gt;&lt;/strong&gt;.tf: Defines the BigQuery table for storing data, with schema auto-detection enabled.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;bucket.tf&lt;/code&gt;&lt;/strong&gt;: Defines another bucket for Cloud Storage, used for data ingestion purposes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;variables.tf&lt;/code&gt;&lt;/strong&gt;: Defines variables such as project ID, region, topic name, and subscription name to make the configuration flexible.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;terraform.tfvars&lt;/code&gt;&lt;/strong&gt;: This file contains the values for the variables defined in &lt;code&gt;variables.tf&lt;/code&gt;, making it easy to customize for different environments.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;cloud-function-overview&#34;&gt;Cloud Function Overview
&lt;/h2&gt;&lt;p&gt;The Cloud Function is triggered when a JSON file is uploaded to the Cloud Storage bucket. It loads the data into BigQuery, automatically detecting the schema of the JSON file.&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.terraform.io/downloads&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Terraform&lt;/a&gt; v1.0.0 or later&lt;/li&gt;
&lt;li&gt;A Google Cloud account&lt;/li&gt;
&lt;li&gt;A Google Cloud project with billing enabled&lt;/li&gt;
&lt;li&gt;Google Cloud SDK installed on your local machine&lt;/li&gt;
&lt;li&gt;A service account with appropriate permissions (Pub/Sub, Cloud Functions, BigQuery, Storage)&lt;/li&gt;
&lt;li&gt;Zip file containing the Cloud Function code (main.py and requirements.txt)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;how-to-use&#34;&gt;How to Use
&lt;/h2&gt;&lt;h3 id=&#34;terraform-setup&#34;&gt;Terraform Setup
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Clone the repository&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git clone https://github.com/imadharir/gcp-data-pipeline-stock-market.git
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; gcp-data-pipeline-stock-market
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Install Terraform&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Set up a virtual environment&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;python3 -m venv venv
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;venv&lt;span class=&#34;se&#34;&gt;\S&lt;/span&gt;cripts&lt;span class=&#34;se&#34;&gt;\a&lt;/span&gt;ctivate
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Install dependencies:&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install -r requirements.txt
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Grant permissions to the Google Cloud Function service account&lt;/strong&gt;:
Ensure that the service account used by Google Cloud Function has the necessary permissions to access Pub/Sub, BigQuery, and Cloud Storage.
You can do this by adding the following roles to the service account: &lt;code&gt;Pub/Sub Publisher&lt;/code&gt;, &lt;code&gt;Pub/Sub Subscriber&lt;/code&gt;, &lt;code&gt;BigQuery Data Editor&lt;/code&gt;, &lt;code&gt;Storage Object Admin&lt;/code&gt;.
The default service account is typically:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;PROJECT_ID&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;@appspot.gserviceaccount.com
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Prepare the environment&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;GOOGLE_APPLICATION_CREDENTIALS&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;path/to/your-service-account-key.json&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Initialize Terraform&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;terraform init
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Plan the infrasctructure&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;terraform plan
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Review the changes that Terraform will make.&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Apply the infrastructure&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;terraform apply
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Confirm the application by typing &amp;lsquo;yes&amp;rsquo; when prompted.&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Upload the Cloud Function zip file&lt;/strong&gt;:
Ensure the zip file containing the Cloud Function code (main.py, requirements.txt) is in the correct path and gets uploaded to the specified bucket.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;dbt-setup&#34;&gt;dbt Setup
&lt;/h3&gt;&lt;p&gt;This section describes the integration of dbt (Data Build Tool) for data transformation and modeling within the project.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Set &lt;code&gt;DBT_PROFILES_DIR&lt;/code&gt; environment variable&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Change directory:&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; dbt_integration
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;&lt;strong&gt;Modify the file &lt;code&gt;profiles.yml&lt;/code&gt; with your own connection credentials:&lt;/strong&gt;
A &lt;code&gt;profiles.yml&lt;/code&gt; file should be configured with the necessary details for connecting to the BigQuery data warehouse.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Set up Application Default Credentials:&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;gcloud init
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;gcloud auth application-default login
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;&lt;strong&gt;Run dbt commands:&lt;/strong&gt;
&lt;strong&gt;Models&lt;/strong&gt;: The &lt;code&gt;myModel.sql&lt;/code&gt; file contains the transformations applied to the stock market data to clean, aggregate, and enhance the dataset.
&lt;strong&gt;Tests&lt;/strong&gt;: Custom tests, such as &lt;code&gt;not_null_all_columns.sql&lt;/code&gt;, have been implemented to validate the data integrity and ensure no null values are present in the critical columns.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;dbt run
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;dbt &lt;span class=&#34;nb&#34;&gt;test&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Or&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;dbt build
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;cleanup&#34;&gt;Cleanup
&lt;/h2&gt;&lt;p&gt;To delete the resources created by Terraform, you can run:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;terraform destroy
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;repo&#34;&gt;Repo
&lt;/h2&gt;&lt;p&gt;ðŸ‘‰ &lt;a class=&#34;link&#34; href=&#34;https://github.com/imadharir/gcp-data-pipeline-stock-market.git&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Github Repository&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
