<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Data Engineering on Imad Harir</title>
        <link>https://imadharir.github.io/categories/data-engineering/</link>
        <description>Recent content in Data Engineering on Imad Harir</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <lastBuildDate>Mon, 30 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://imadharir.github.io/categories/data-engineering/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Amazon Books Scraper</title>
        <link>https://imadharir.github.io/p/amazon-books-scraper/</link>
        <pubDate>Mon, 30 Sep 2024 00:00:00 +0000</pubDate>
        
        <guid>https://imadharir.github.io/p/amazon-books-scraper/</guid>
        <description>&lt;img src="https://imadharir.github.io/p/amazon-books-scraper/AmazonBookScraper.png" alt="Featured image of post Amazon Books Scraper" /&gt;&lt;h1 id=&#34;amazon-book-scraper-and-storage&#34;&gt;Amazon Book Scraper and Storage
&lt;/h1&gt;&lt;h2 id=&#34;project-overview&#34;&gt;Project Overview
&lt;/h2&gt;&lt;p&gt;The Amazon Book Scraper and Storage project is an automated data pipeline that scrapes book information from Amazon and stores it in a PostgreSQL database. The project leverages Apache Airflow for orchestration and scheduling of the scraping and data ingestion process.&lt;/p&gt;
&lt;h2 id=&#34;table-of-contents&#34;&gt;Table of Contents
&lt;/h2&gt;&lt;ol&gt;
  &lt;li&gt;Project Overview&lt;/li&gt;
  &lt;li&gt;Architecture&lt;/li&gt;
  &lt;li&gt;Features&lt;/li&gt;
  &lt;li&gt;Technologies Used&lt;/li&gt;
  &lt;li&gt;Setup and Installation&lt;/li&gt;
  &lt;li&gt;Usage&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;architecture&#34;&gt;Architecture
&lt;/h2&gt;&lt;p&gt;
The project follows a simple ETL (Extract, Transform, Load) architecture:
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Extract:&lt;/strong&gt; Data is scraped from Amazon using a Python script with &lt;code&gt;requests&lt;/code&gt; and &lt;code&gt;BeautifulSoup&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Transform:&lt;/strong&gt; The extracted data is cleaned and structured using &lt;code&gt;pandas&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Load:&lt;/strong&gt; The structured data is inserted into a PostgreSQL database using &lt;code&gt;airflow.providers.postgres.hooks.postgres&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://imadharir.github.io/p/amazon-books-scraper/AmazonBookScraper.png&#34;
	width=&#34;1141&#34;
	height=&#34;922&#34;
	srcset=&#34;https://imadharir.github.io/p/amazon-books-scraper/AmazonBookScraper_hu797588405123154000.png 480w, https://imadharir.github.io/p/amazon-books-scraper/AmazonBookScraper_hu9161034162332869920.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Architecture&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;123&#34;
		data-flex-basis=&#34;297px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;high-level-architecture-components&#34;&gt;High-Level Architecture Components:
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Airflow DAG:&lt;/strong&gt; Manages and schedules the daily data pipeline tasks.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Python Scraper:&lt;/strong&gt; Extracts book data (title, author, price, rating) from Amazon.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PostgreSQL Database:&lt;/strong&gt; Stores the scraped book data.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Google Cloud Composer:&lt;/strong&gt; Manages the Airflow orchestration in a cloud environment.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;features&#34;&gt;Features
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Automated Daily Scraping:&lt;/strong&gt; The pipeline runs daily, automatically scraping new book data.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data Deduplication:&lt;/strong&gt; Ensures only new books are added during each subsequent run.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cloud-Based Orchestration:&lt;/strong&gt; Uses Google Cloud Composer for cloud-based execution and management.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Modular Design:&lt;/strong&gt; Components are decoupled, making it easy to extend or modify parts of the pipeline.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;technologies-used&#34;&gt;Technologies Used
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Apache Airflow:&lt;/strong&gt; Orchestrates and schedules the tasks.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Python:&lt;/strong&gt; Implements the scraping logic using requests and BeautifulSoup.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PostgreSQL:&lt;/strong&gt; Stores the book data for further analysis.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Google Cloud Composer:&lt;/strong&gt; Manages the Airflow environment on Google Cloud.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Terraform:&lt;/strong&gt; Automates the infrastructure setup.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;setup-and-installation&#34;&gt;Setup and Installation
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; This setup guide is intended for Windows users. If you&amp;rsquo;re using a different operating system, please refer to the official documentation for installation instructions specific to your platform.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;prerequisites&#34;&gt;Prerequisites
&lt;/h3&gt;&lt;p&gt;Before starting the project setup, ensure you have the following tools and accounts configured:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Google Cloud Platform (GCP) Account&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A GCP account is required to create and manage cloud resources. If you don&amp;rsquo;t have an account, create one at &lt;a class=&#34;link&#34; href=&#34;https://cloud.google.com&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;cloud.google.com&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Google Cloud Project&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Create a new GCP project or use an existing one. Make a note of the project ID, as it will be used throughout the setup.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Install Terraform&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Download and install Terraform from &lt;a class=&#34;link&#34; href=&#34;https://www.terraform.io/downloads.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;terraform.io&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Verify the installation by running:
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;terraform -v
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Install Google Cloud SDK (&lt;code&gt;gcloud&lt;/code&gt;)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Install the Google Cloud SDK by following the instructions &lt;a class=&#34;link&#34; href=&#34;https://cloud.google.com/sdk/docs/install&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Initialize &lt;code&gt;gcloud&lt;/code&gt; and set the default project:
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;gcloud init
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;gcloud config &lt;span class=&#34;nb&#34;&gt;set&lt;/span&gt; project &amp;lt;YOUR_PROJECT_ID&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Enable Required APIs&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ensure the following APIs are enabled in your GCP project:
&lt;ul&gt;
&lt;li&gt;Compute Engine API&lt;/li&gt;
&lt;li&gt;Cloud Composer API&lt;/li&gt;
&lt;li&gt;Cloud SQL Admin API&lt;/li&gt;
&lt;li&gt;Identity and Access Management (IAM) API&lt;/li&gt;
&lt;li&gt;Cloud Storage API&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Enable them using the &lt;code&gt;gcloud&lt;/code&gt; command:
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;gcloud services &lt;span class=&#34;nb&#34;&gt;enable&lt;/span&gt; compute.googleapis.com &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;                       composer.googleapis.com &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;                       sqladmin.googleapis.com &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;                       iam.googleapis.com &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;                       storage.googleapis.com
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;step-1-set-up-service-account&#34;&gt;Step 1: Set Up Service Account
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Create a Service Account&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Go to the &lt;a class=&#34;link&#34; href=&#34;https://console.cloud.google.com/iam-admin/serviceaccounts&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;IAM &amp;amp; Admin Console&lt;/a&gt; and create a new service account with the following details:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Name&lt;/strong&gt;: &lt;code&gt;terraform-admin&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Role&lt;/strong&gt;: &lt;code&gt;Owner&lt;/code&gt;, &lt;code&gt;roles/roleAdmin&lt;/code&gt;, &lt;code&gt;roles/iam.securityAdmin&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Generate a JSON Key&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;After creating the service account, generate a JSON key and download it.&lt;/li&gt;
&lt;li&gt;Store the JSON key in a secure location, as it will be used by Terraform to authenticate with GCP.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Set Environment Variable for Authentication&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Set the &lt;code&gt;GOOGLE_APPLICATION_CREDENTIALS&lt;/code&gt; environment variable to the path of your service account key file:
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;GOOGLE_APPLICATION_CREDENTIALS&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/path/to/service-account-key.json&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;step-2-clone-the-repository-and-configure-terraform&#34;&gt;Step 2: Clone the Repository and Configure Terraform
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Clone the Project Repository&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Clone the repository containing the Terraform configurations and DAGs:
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git clone https://github.com/imadharir/AmazonBookScaperETL.git
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; AmazonBookScaperETL
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Update &lt;code&gt;terraform.tfvars&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Create or edit a &lt;code&gt;terraform.tfvars&lt;/code&gt; file in the root directory with your project-specific values:
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-hcl&#34; data-lang=&#34;hcl&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;project_id&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;lt;YOUR_PROJECT_ID&amp;gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;region&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;us-central1&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;credentials_file&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;/path/to/service-account-key.json&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Initialize and Validate Terraform Configuration&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Initialize the Terraform workspace:
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;terraform init
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;Validate the configuration to ensure everything is set up correctly:
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;terraform validate
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;step-3-deploy-the-infrastructure&#34;&gt;Step 3: Deploy the Infrastructure
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Deploy the Resources&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Deploy the infrastructure using Terraform:
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;terraform apply
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;Review the plan and confirm by typing &lt;code&gt;yes&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Verify the Deployment&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Check the GCP console to ensure that all the resources (e.g., Cloud Composer environment, Cloud SQL instance, VPC, etc.) have been created successfully.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;step-4-cloud-composer-configuration&#34;&gt;Step 4: Cloud Composer Configuration
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Configure Airflow Connections&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If you didn&amp;rsquo;t create the Airflow connections using Terraform, go to the &lt;a class=&#34;link&#34; href=&#34;https://console.cloud.google.com/composer/environments&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Cloud Composer UI&lt;/a&gt; and configure the necessary connections:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Postgres Connection&lt;/strong&gt;:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Conn Id&lt;/strong&gt;: &lt;code&gt;books_connection&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Conn Type&lt;/strong&gt;: &lt;code&gt;Postgres&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Host&lt;/strong&gt;: &lt;code&gt;&amp;lt;Your Cloud SQL Internal IP&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Schema&lt;/strong&gt;: &lt;code&gt;amazon_books&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Login&lt;/strong&gt;: &lt;code&gt;postgres&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Password&lt;/strong&gt;: &lt;code&gt;&amp;lt;Your Password&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Port&lt;/strong&gt;: &lt;code&gt;5432&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Upload DAG Files&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Upload the DAG file(s) to the &lt;code&gt;dags&lt;/code&gt; folder in the Cloud Composer bucket:
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;gsutil cp /local/path/to/dag.py gs://&amp;lt;COMPOSER_BUCKET_NAME&amp;gt;/dags/
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;step-5-monitoring-and-logs&#34;&gt;Step 5: Monitoring and Logs
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Monitor the DAG Runs&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Navigate to the &lt;a class=&#34;link&#34; href=&#34;https://console.cloud.google.com/composer/environments&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Airflow UI&lt;/a&gt; and monitor your DAG runs.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;step-6-clean-up-resources&#34;&gt;Step 6: Clean Up Resources
&lt;/h3&gt;&lt;p&gt;To avoid incurring charges for unused resources, remember to delete the GCP project or individual resources when the project is no longer needed:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;terraform destroy
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;usage&#34;&gt;Usage
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;The project runs on a daily basis, ensuring the database is updated with new book entries.&lt;/li&gt;
&lt;li&gt;Can be used for trend analysis, pricing insights, or recommendation systems.&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        
    </channel>
</rss>
